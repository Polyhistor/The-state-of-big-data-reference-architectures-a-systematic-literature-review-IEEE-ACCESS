@inproceedings{10.1145/3147213.3155013,
author = {Chang, Wo},
title = {NIST Big Data Reference Architecture for Analytics and Beyond},
year = {2017},
isbn = {9781450351492},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147213.3155013},
doi = {10.1145/3147213.3155013},
abstract = {Big Data is the term used to describe the deluge of data in our networked, digitized, sensor-laden, information driven world. There is a broad agreement among commercial, academic, and government leaders about the remarkable potential of "Big Data" to spark innovation, fuel commerce, and drive progress. The availability of vast data resources carries the potential to answer questions previously out of reach. However, there is also broad agreement on the ability of Big Data to overwhelm traditional approaches. Big Data architectures come in many shapes and forms ranging from academic research settings to product-oriented workflows. With massive-scale dynamic data being generate from social media, Internet of Things, Smart Cities, and others, it is critical to analyze these data in real-time and provide proactive decision. With the advancement of computer architecture in multi-cores and GPUs, and fast communication between CPUs and GPUs, parallel processing utilizes these platforms could optimize resources at a reduced time. This presentation will provide the past, current, and future activities of the NIST Big Data Public Working Group (NBD-PWG) and how the NIST Reference Architecture may address the rate at which data volumes, speeds, and complexity are growing requires new forms of computing infrastructure to enable Big Data analytics interoperability such that analytics tools can be re-usable, deployable, and operational. The focus of NBD-PWG is to form a community of interest from industry, academia, and government, with the goal of developing consensus definitions, taxonomies, secure reference architectures, and standards roadmap which would create vendor-neutral, technology and infrastructure agnostic framework. The aim is to enable Big Data stakeholders to pick-and-choose best analytics tools for their processing under the most suitable computing platforms and clusters while allowing value-additions from Big Data service providers and flow of data between the stakeholders in a cohesive and secure manner.},
booktitle = {Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {3},
numpages = {1},
keywords = {big data reference architecture, big data analytics, many cpus/cores/gpus, high-performance computing},
location = {Austin, Texas, USA},
series = {UCC '17}
}

@inproceedings{10.1145/2896825.2896834,
author = {Klein, John and Buglak, Ross and Blockow, David and Wuttke, Troy and Cooper, Brenton},
title = {A Reference Architecture for Big Data Systems in the National Security Domain},
year = {2016},
isbn = {9781450341523},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2896825.2896834},
doi = {10.1145/2896825.2896834},
abstract = {Acquirers, system builders, and other stakeholders of big data systems need to define requirements, develop and evaluate solutions, and integrate systems together. A reference architecture enables these software engineering activities by standardizing nomenclature, defining key solution elements and their relationships, collecting relevant solution patterns, and classifying existing technologies. Within the national security domain, existing reference architectures for big data systems have not been useful because they are too general or are not vendor-neutral. We present a reference architecture for big data systems that is focused on addressing typical national defence requirements and that is vendor-neutral, and we demonstrate how to use this reference architecture to define solutions in one mission area.},
booktitle = {Proceedings of the 2nd International Workshop on BIG Data Software Engineering},
pages = {51–57},
numpages = {7},
keywords = {reference architecture, big data},
location = {Austin, Texas},
series = {BIGDSE '16}
}

@inproceedings{10.1145/3345252.3345282,
author = {Petrova-Antonova, Dessislava and Krasteva, Iva and Ilieva, Sylvia and Pavlova, Irena},
title = {Conceptual Architecture of GATE Big Data Platform},
year = {2019},
isbn = {9781450371490},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3345252.3345282},
doi = {10.1145/3345252.3345282},
abstract = {Today we experience a data-driven society. All human activities, industrial processes and research lead to data generation of unprecedented scale, spurring new products, services and businesses. Big Data and its application have been a target for European Commission -- with more than 100 FP7 and about 50 H2020 funded projects under Big Data domain. GATE project aims to establish and sustain in the long run a Centre of Excellence as collaborative environment for conducting Big Data research and innovation, facilitated by GATE platform and Innovation Labs. This paper proposes a conceptual architecture of GATE platform, that is holistic, symbiotic, open, evolving and data-integrated. It is also modular and with component-based design that allows to position a mix of products and tools from different providers. GATE platform will enable start-ups, SMEs and large enterprises, as well as other organizations in a wide range of sectors, to build advanced Data driven services and applications. The usability of the proposed architecture is proven through a development of a sample time series data visualization application. Its architecture follows the proposed one through implementation of required components using open technology stack.},
booktitle = {Proceedings of the 20th International Conference on Computer Systems and Technologies},
pages = {261–268},
numpages = {8},
keywords = {Big Data Value Chain, Big Data, GATE Platform, Emerging Architectures, Smart City},
location = {Ruse, Bulgaria},
series = {CompSysTech '19}
}

@inproceedings{10.1145/3264437.3264474,
author = {Dauda, Ahmed and Mclean, Scott and Almehmadi, Abdulaziz and El-Khatib, Khalil},
title = {Big Data Analytics Architecture for Security Intelligence},
year = {2018},
isbn = {9781450366083},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3264437.3264474},
doi = {10.1145/3264437.3264474},
abstract = {The need for security1 continues to grow in distributed computing. Today's security solutions require greater scalability and convenience in cloud-computing architectures, in addition to the ability to store and process larger volumes of data to address very sophisticated attacks. This paper explores some of the existing architectures for big data intelligence analytics, and proposes an architecture that promises to provide greater security for data intensive environments. The architecture is designed to leverage the wealth in the multi-source information for security intelligence.},
booktitle = {Proceedings of the 11th International Conference on Security of Information and Networks},
articleno = {19},
numpages = {4},
keywords = {analytics architecture, Big Data, Security Intelligence},
location = {Cardiff, United Kingdom},
series = {SIN '18}
}

@inproceedings{10.1145/3132498.3132510,
author = {Sena, Bruno and Allian, Ana Paula and Nakagawa, Elisa Yumi},
title = {Characterizing Big Data Software Architectures: A Systematic Mapping Study},
year = {2017},
isbn = {9781450353250},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3132498.3132510},
doi = {10.1145/3132498.3132510},
abstract = {Big data is a broad term for large, dynamic, and complex data sets that have brought great challenges to be addressed by traditional software systems. It has also demanded advanced software architectures (i.e., the big data software architectures) prepared to deal with the continuous expansion of the volume of data as well as to take advantage of new technologies for big data context. However, the main characteristics, basic requirements, and modules and organization of big data architectures are not still widely known. Besides that, no detailed overview about them is available. The main contribution of this paper is to present the state of the art related to big data software architectures; for this, we conducted a Systematic Mapping Study. As results, an essential set of eight requirements for big data architectures was identified, besides a collection of five modules that are fundamental to adequately enable the data flow. We also intend these results can guide architects in the development of software systems for this new challenging scenario of big data management.},
booktitle = {Proceedings of the 11th Brazilian Symposium on Software Components, Architectures, and Reuse},
articleno = {9},
numpages = {10},
keywords = {software architecture, systematic mapping study, reference architecture, big data system},
location = {Fortaleza, Cear\'{a}, Brazil},
series = {SBCARS '17}
}

@inproceedings{10.1145/3063955.3063968,
author = {Wang, Hongzhi and Gao, Hong and Yin, Shenjun and Zhu, Jie},
title = {The Design of Course Architecture for Big Data},
year = {2017},
isbn = {9781450348737},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3063955.3063968},
doi = {10.1145/3063955.3063968},
abstract = {Big data is one of the hottest topic in not only academic but also enterprise, which provide grate requirements for the people with knowledge and experiences of big data. However, current education architecture of computer science could not provide sufficient training for big data. For the education for people suitable for big data era, we attempt to design a novel course architecture. Such course architecture will not change the skeleton of traditional course architecture of computer science but just add content and subjects that is adaptive for big data. In this paper, we discuss the goal, architecture and content of the course architecture.},
booktitle = {Proceedings of the ACM Turing 50th Celebration Conference - China},
articleno = {13},
numpages = {6},
keywords = {big data, data science, course architecture},
location = {Shanghai, China},
series = {ACM TUR-C '17}
}

@inproceedings{10.1145/2968456.2976765,
author = {Neshatpour, Katayoun and Sasan, Avesta and Homayoun, Houman},
title = {Big Data Analytics on Heterogeneous Accelerator Architectures},
year = {2016},
isbn = {9781450344838},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2968456.2976765},
doi = {10.1145/2968456.2976765},
abstract = {In this paper, we present the implementation of big data analytics applications in a heterogeneous CPU+FPGA accelerator architecture. We develop the MapReduce implementation of K-means, K nearest neighbor, support vector machine and Naive Bayes in a Hadoop Streaming environment that allows developing mapper/reducer functions in a non-Java based language suited for interfacing with FPGA-based hardware accelerating environment. We present a full implementation of the HW+SW mappers on the Zynq FPGA platform. A promising speedup as well as energy-efficiency gains of upto 4.5X and 22X is achieved, respectively, in an end-to-end Hadoop implementation.},
booktitle = {Proceedings of the Eleventh IEEE/ACM/IFIP International Conference on Hardware/Software Codesign and System Synthesis},
articleno = {16},
numpages = {3},
location = {Pittsburgh, Pennsylvania},
series = {CODES '16}
}

@inproceedings{10.1145/3492324.3494169,
author = {Bhat, Aimer and Park, Heeki and Roy, Madhumonti},
title = {Evaluating Serverless Architecture for Big Data Enterprise Applications},
year = {2021},
isbn = {9781450391641},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3492324.3494169},
doi = {10.1145/3492324.3494169},
abstract = { Migration of enterprise applications to the cloud has been driven by a myriad of benefits ranging from availability of infinite computing resources to the elimination of upfront CapEx cost. However, many users still face the burden of complex framework knowledge requirement to efficiently deploy applications in the cloud. In this paper, we investigate serverless computing for performing large scale data processing with cloud-native primitives. Serverless computing environment abstracts all infrastructure handling, simplifying developers’ work who aspire to deploy applications on the cloud. With dynamic input load on the system, serverless architecture has promise to provide better resource utilization and lower costs.},
booktitle = {2021 IEEE/ACM 8th International Conference on Big Data Computing, Applications and Technologies (BDCAT '21)},
pages = {1–8},
numpages = {8},
keywords = {Big data processing, AWS Lambda, Serverless computing, MapReduce, Enterprise applications, cloud computing, Function as a Service, load variations},
location = {Leicester, United Kingdom},
series = {BDCAT '21}
}

@inproceedings{10.1145/3130218.3130236,
author = {Doppa, Janardhan Rao and Kim, Ryan Gary and Isakov, Mihailo and Kinsy, Michel A. and Kwon, Hyouk Jun and Krishna, Tushar},
title = {Adaptive Manycore Architectures for Big Data Computing},
year = {2017},
isbn = {9781450349840},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3130218.3130236},
doi = {10.1145/3130218.3130236},
abstract = {This work presents a cross-layer design of an adaptive manycore architecture to address the computational needs of emerging big data applications within the technological constraints of power and reliability. From the circuits end, we present links with reconfigurable repeaters that allow single-cycle traversals across multiple hops, creating fast single-cycle paths on demand. At the microarchitecture end, we present a router with bi-directional links, unified virtual channel (VC) structure, and the ability to perform self-monitoring and self-configuration around faults. We present our vision for self-aware manycore architectures and argue that machine learning techniques are very appropriate to efficiently control various configurable on-chip resources in order to realize this vision. We provide concrete learning algorithms for core and NoC reconfiguration; and dynamic power management to improve the performance, energy-efficiency, and reliability over static designs to meet the demands of big data computing. We also discuss future challenges to push the state-of-the-art on fully adaptive manycore architectures.},
booktitle = {Proceedings of the Eleventh IEEE/ACM International Symposium on Networks-on-Chip},
articleno = {20},
numpages = {8},
keywords = {Adaptive manycore architectures, Machine learning, Big data computing, Power management, Interconnect networks},
location = {Seoul, Republic of Korea},
series = {NOCS '17}
}

@inproceedings{10.1109/CCGRID.2017.107,
author = {Haroun, Amir and Mostefaoui, Ahmed and Dessables, Fran\c{c}ois},
title = {A Big Data Architecture for Automotive Applications: PSA Group Deployment Experience},
year = {2017},
isbn = {9781509066100},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2017.107},
doi = {10.1109/CCGRID.2017.107},
abstract = {Vehicles have become moving sensor platforms collecting huge volumes of data from their various embedded sensors. This data has a great value for automotive manufacturers and vehicles owners. Indeed, connected vehicles data can be used in a large broad of automotive services ranging from safety services to well-being services (e.g. fatigue detection). However, vehicle fleets send big volumes of data that traditional computing and storage approaches are not able to manage efficiently. In this paper, we present the experience of the PSA Group1 on leveraging big data in automotive context. We describe in depth the big data architecture deployed within the PSA Group and the underlaying technologies/products used in each component.},
booktitle = {Proceedings of the 17th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {921–928},
numpages = {8},
keywords = {Reference Architecture, Connected Vehicles, Big Data},
location = {Madrid, Spain},
series = {CCGrid '17}
}

@inproceedings{10.1145/3030207.3053670,
author = {Singhal, Rekha and Kunde, Shruti},
title = {Technology Migration Challenges in a Big Data Architecture Stack},
year = {2017},
isbn = {9781450344043},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3030207.3053670},
doi = {10.1145/3030207.3053670},
abstract = {Application and/or data migration is a result of limitations in existing system architecture to handle new requirements and the availability of newer, more efficient technology. In any big data architecture, technology migration is staggered across multiple levels and poses functional (related to components of the architecture and underlying infrastructure) and non-functional (QoS) challenges such as availability, reliability and performance guarantees in the target architecture. In this paper, (1) we outline a big data architecture stack and identify research problems arising out of the technology migration in this scenario (2) we propose a smart rule engine system which facilitates the decision making process for the technology to be used at different layers in the architecture during migration.},
booktitle = {Proceedings of the 8th ACM/SPEC on International Conference on Performance Engineering},
pages = {159–160},
numpages = {2},
keywords = {performance, big data, migration},
location = {L'Aquila, Italy},
series = {ICPE '17}
}

@inproceedings{10.1145/3399205.3399225,
author = {Elhassan, Jamal and Aniss, Moumen and Jamal, Chao},
title = {Big Data Analytic Architecture for Water Resources Management: A Systematic Review},
year = {2020},
isbn = {9781450375788},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3399205.3399225},
doi = {10.1145/3399205.3399225},
abstract = {The management of hydraulic resources and especially water resources has become a major priority for decision-makers and planners at the international level. The advent of new technologies such as big data analytics and IoT has led to exponential changes in the volume of data generated daily in real-time, this monitoring information has potential significance if it is collected and aggregated effectively. The data collected are increasingly complex and represent a central government issue, developing water resource management strategies. The exploitation of this type of data requires new methods of analysis and knowledge discovery. This work presents a literature review of articles related to big data and water resources. Also, we present our proposition of a new architecture to conduct a big data analytic. In conclusion, we discuss the impact of using this technology in water resource management.},
booktitle = {Proceedings of the 4th Edition of International Conference on Geo-IT and Water Resources 2020, Geo-IT and Water Resources 2020},
articleno = {19},
numpages = {5},
keywords = {water resources, big data analytics, real-time, IoT},
location = {Al-Hoceima, Morocco},
series = {GEOIT4W-2020}
}

@inproceedings{10.1145/2903150.2908078,
author = {Homayoun, Houman},
title = {Heterogeneous Chip Multiprocessor Architectures for Big Data Applications},
year = {2016},
isbn = {9781450341288},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2903150.2908078},
doi = {10.1145/2903150.2908078},
abstract = {Emerging big data analytics applications require a significant amount of server computational power. The costs of building and running a computing server to process big data and the capacity to which we can scale it are driven in large part by those computational resources. However, big data applications share many characteristics that are fundamentally different from traditional desktop, parallel, and scale-out applications. Big data analytics applications rely heavily on specific deep machine learning and data mining algorithms, and are running a complex and deep software stack with various components (e.g. Hadoop, Spark, MPI, Hbase, Impala, MySQL, Hive, Shark, Apache, and MangoDB) that are bound together with a runtime software system and interact significantly with I/O and OS, exhibiting high computational intensity, memory intensity, I/O intensity and control intensity. Current server designs, based on commodity homogeneous processors, will not be the most efficient in terms of performance/watt for this emerging class of applications. In other domains, heterogeneous architectures have emerged as a promising solution to enhance energy-efficiency by allowing each application to run on a core that matches resource needs more closely than a one-size-fits-all core. A heterogeneous architecture integrates cores with various micro-architectures and accelerators to provide more opportunity for efficient workload mapping. In this work, through methodical investigation of power and performance measurements, and comprehensive system level characterization, we demonstrate that a heterogeneous architecture combining high performance big and low power little cores is required for efficient big data analytics applications processing, and in particular in the presence of accelerators and near real-time performance constraints.},
booktitle = {Proceedings of the ACM International Conference on Computing Frontiers},
pages = {400–405},
numpages = {6},
keywords = {power, performance, application characterization, accelerator, big data, heterogeneous architectures},
location = {Como, Italy},
series = {CF '16}
}

@inproceedings{10.1145/3147234.3151010,
author = {Gong, Yikai and Rimba, Paul and Sinnott, Richard},
title = {A Big Data Architecture for Near Real-Time Traffic Analytics},
year = {2017},
isbn = {9781450351959},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3147234.3151010},
doi = {10.1145/3147234.3151010},
abstract = {Big data is a popular research topic that has brought about a range of new IT challenges and opportunities. The transport domain is one area that has much to benefit from big data platforms. It requires capabilities for processing voluminous amounts of heterogeneous data that is often created in near real time and at high velocity from a multitude of distributed sensors. It can also require the application of performance-oriented spatial data processing of such data. In this paper, we present a platform (SMASH) that tackles many of the specific challenges raised by the transport domain. We present a range of case studies applying SMASH to transport and other data used to understand traffic phenomenon across the State of Victoria, Australia. The novelty of this work is that this Cloud-based platform is not designed for a specific type of data or for a specific form of data processing. Rather it supports a range of data flavours with a range of data processing possibilities. In particular we show how the platform can be used for analyzing social media data used for traffic jam identification through spatial and temporal clustering tweets on the road network and compare the results with official real-time traffic data based on the Sydney Coordinated Adaptive Traffic System (SCATS - www.scats.com.au) that has been rolled out across Victoria.},
booktitle = {Companion Proceedings of The10th International Conference on Utility and Cloud Computing},
pages = {157–162},
numpages = {6},
keywords = {big data, traffic analysis, cloud},
location = {Austin, Texas, USA},
series = {UCC '17 Companion}
}

@inproceedings{10.1109/CCGRID.2018.00052,
author = {Al-Jaroodi, Jameela and Mohamed, Nader},
title = {Service-Oriented Architecture for Big Data Analytics in Smart Cities},
year = {2018},
isbn = {9781538658154},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/CCGRID.2018.00052},
doi = {10.1109/CCGRID.2018.00052},
abstract = {A smart city has recently become an aspiration for many cities around the world. These cities are looking to apply the smart city concept to improve sustainability, quality of life for residents, and economic development. The smart city concept depends on employing a wide range of advanced technologies to improve the performance of various services and activities such as transportation, energy, healthcare, and education, while at the same time improve the city's resources utilization and initiate new business opportunities. One of the promising technologies to support such efforts is the big data technology. Effective and intelligent use of big data accumulated over time in various sectors can offer many advantages to enhance decision making in smart cities. In this paper we identify the different types of decision making processes involved in smart cities. Then we propose a service-oriented architecture to support big data analytics for decision making in smart cities. This architecture allows for integrating different technologies such as fog and cloud computing to support different types of analytics and decision-making operations needed to effectively utilize available big data. It provides different functions and capabilities to use big data and provide smart capabilities as services that the architecture supports. As a result, different big data applications will be able to access and use these services for varying proposes within the smart city.},
booktitle = {Proceedings of the 18th IEEE/ACM International Symposium on Cluster, Cloud and Grid Computing},
pages = {633–640},
numpages = {8},
keywords = {middleware, service-oriented architecture, big data, cloud computing, smart city, fog computing},
location = {Washington, District of Columbia},
series = {CCGrid '18}
}

@inproceedings{10.1145/3286606.3286841,
author = {Elyusufi, Z. and Elyusufi, Y. and Aitkbir, M.},
title = {Customer Profiling Using CEP Architecture in a Big Data Context},
year = {2018},
isbn = {9781450365628},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3286606.3286841},
doi = {10.1145/3286606.3286841},
abstract = {Today Big Data tools are not just a phenomenon of the massive information collection; they are also the best way to approach a customer target. These technologies allow the profiling of the customers of an organization thanks to the histories of purchases, the products that they consult; the data that they share through the social networks. They also make it possible to anticipate the purchase of actions via behavioral analysis. Therefore, the combination of the power of CRM and the performance of BIG DATA tools brings a great added value for customers profile analysis, especially if it is about events triggered in real time. It is in this context that the present work is positioned. Our goal is to intercept events (customer behaviors) and analyze them in real time. We will use the Complex Events Process (CEP) architecture that perfectly meets this need. In order to successfully implement our CEP architecture, we will use the ontology approach.},
booktitle = {Proceedings of the 3rd International Conference on Smart City Applications},
articleno = {64},
numpages = {6},
keywords = {CRM, Big Data, Ontology, CEP, Profiling},
location = {Tetouan, Morocco},
series = {SCA '18}
}

@inproceedings{10.1145/3423603.3424049,
author = {Aissa, Mohamed Mehdi Ben and Sfaxi, Lilia and Robbana, Riadh},
title = {Decisional Architectures from Business Intelligence to Big Data: Challenges and Opportunities},
year = {2020},
isbn = {9781405377539},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3423603.3424049},
doi = {10.1145/3423603.3424049},
abstract = {Information is one of the most important factors in business success, hence the importance of the Business Intelligence (BI) domain in order to simplify the decision making and make it more relevant. Decisional systems have been used for several years to help decision-makers access, analyze and extract value from the data that their organisation accumulated through the years. The success gained by these types of systems caused the establishment of a well-known architecture and development chain, and the proliferation of tools and methodologies that have proven their value. Nonetheless, in some use cases, the classical decisional architecture shows some shortcomings. In fact, the traditional storage and processing models in Business Intelligence systems are not sufficient anymore when confronted with data that becomes more and more massive, varied and with a high velocity. This is where Big Data solutions can be of great use. In fact, these solutions have proven their efficiency when dealing with enormous constantly increasing amounts of data with a changing schema. Our goal in this article is to show the various manners to integrate big data solutions into the decisional world, and to help architects choose which architecture corresponds better to their needs, by taking into consideration the environmental, technical and functional constraints they are faced with.},
booktitle = {Proceedings of the 2nd International Conference on Digital Tools &amp; Uses Congress},
articleno = {12},
numpages = {9},
keywords = {data warehouse, data lake, decision tree for decisional architectures, decisional systems, software architecture, big data, business intelligence, OLAP},
location = {Virtual Event, Tunisia},
series = {DTUC '20}
}

@inproceedings{10.1145/3085228.3085275,
author = {Gong, Yiwei and Janssen, Marijn},
title = {Enterprise Architectures for Supporting the Adoption of Big Data},
year = {2017},
isbn = {9781450353175},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3085228.3085275},
doi = {10.1145/3085228.3085275},
abstract = {Governments from all over the world are struggling to take advantage of big data developments. Enterprise Architecture (EA) can be used as an instrument to integrate big data (BD) in the existing business processes and ICT-landscape. In this policy paper, we explore the role of EA in the adoption of BD. For this, we adopted a qualitative case study approach and investigated a large administrative organization that was in the process of adopting BD. We found in our case study that the first attempts were focused on integrating big data in the current landscape, but this encountered too many challenges that halt progress. To overcome the challenges, a separate BD department and accompanying infrastructure was created. The strategy was first to reap the benefits of BD and to understand what should be done, and thereafter integrating the working systems in the existing landscape. The findings suggest that current infrastructures might not be suitable for integrating BD and substantial changes are needed first. In the case the role of BD needed to be first clarified before EA could play a role in adopting BD. EA should deal with the uncertainties and complexities by ensuring a configurable landscape, by providing an incremental approach for adapting the infrastructure step-by-step, before the benefits of big data can be gained. Developing an incremental migration plan was found to be a key aspect for the adoption of BD.},
booktitle = {Proceedings of the 18th Annual International Conference on Digital Government Research},
pages = {505–510},
numpages = {6},
keywords = {e-government, BOLD, infrastructure, enterprise architecture, ICT-architecture, open data, big data},
location = {Staten Island, NY, USA},
series = {dg.o '17}
}

@inproceedings{10.1145/3320326.3320356,
author = {Daki, Houda and El Hannani, Asmaa and Ouahmane, Hassan},
title = {Big-Data Architecture for Electrical Consumption Forecasting in Educational Institutions Buildings},
year = {2019},
isbn = {9781450366458},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3320326.3320356},
doi = {10.1145/3320326.3320356},
abstract = {Recently, educational institutions suffer from high electrical consumption due to their new practices and activities. One of the promising solutions to overcome this challenge is to improve their energy management strategies using smart grids which ensure efficiency, reliability and energy saving. For this same reason, the National School of Applied Sciences of El Jadida -- Morocco has decided to install a private smart grid based on photovoltaic panels that will cover 40% of its electricity needs. But the problem that arises when using this new approach is the high level of complexity in term of data management due to the variety, veracity and the volume of the data. So, to meet these needs the use of Big Data technologies is required. In this paper, we propose a Big Data solution based on Lambda architecture to handle electrical consumption data in the National School of Applied Sciences of El Jadida -- Morocco. This system collects all parameters that might influence electrical consumption with Kafka, then it applies Spark libraries to analyze it. The solution allows also electrical energy forecasting using Spark machine learning library and the data persistence using HBase storage system.},
booktitle = {Proceedings of the 2nd International Conference on Networking, Information Systems &amp; Security},
articleno = {24},
numpages = {6},
keywords = {Spark, Electrical forecasting, Smart grid, Lambda architecture, Machine learning, HBase storage system, Kafka, Big Data},
location = {Rabat, Morocco},
series = {NISS19}
}

@inproceedings{10.1145/3264560.3266428,
author = {Ayvaz, Serkan and Shiha, Mohammed O.},
title = {A Scalable Streaming Big Data Architecture for Real-Time Sentiment Analysis},
year = {2018},
isbn = {9781450364744},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/3264560.3266428},
doi = {10.1145/3264560.3266428},
abstract = {The systems with a short window of opportunity for actions and decisions require developing solutions providing real-time streaming analytics. Real-time big data streaming analytics is a challenging task. In this paper, we propose a streaming big data architecture for real-time social network analysis. As a case study, we investigated the relation between the public opinions on social media about cryptocurrencies and the changes in their prices using lexicon-based sentiment analysis approaches with the goal of assessing the feasibility of predicting the prices of cryptocurrencies. Two different approaches with two lexicons were used for sentiment analysis score calculations to assess the consistency of correlation measures on the collected dataset. Our model indicates that the prediction of cryptocurrency price changes using lexicon-based sentiment analysis methods is not reliable.},
booktitle = {Proceedings of the 2018 2nd International Conference on Cloud and Big Data Computing},
pages = {47–51},
numpages = {5},
keywords = {opinion mining, data streaming, cryptocurrency, big data, sentiment analysis},
location = {Barcelona, Spain},
series = {ICCBDC'18}
}

